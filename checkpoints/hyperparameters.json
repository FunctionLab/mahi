{
    "emb_dim": 512,
    "edge_dim": 35,
    "num_layers": 4,
    "heads": 1,
    "dropout": 0.2,
    "learning_rate": 0.001,
    "weight_decay": 0.0001,
    "batch_size": 128,
    "num_neighbors": [
        20,
        20,
        20,
        20
    ],
    "epochs": 20,
    "masking_ratio": 0.15,
    "norm_type": "layernorm",
    "global_skip": false,
    "use_residual": true
}